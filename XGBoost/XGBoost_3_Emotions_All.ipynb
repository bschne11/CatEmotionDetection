{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-FWTYEUoyJ5"
      },
      "outputs": [],
      "source": [
        "# Install required packages for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGdFhpgkiIBK"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KktEYBWrIMp"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, mean_absolute_percentage_error\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "import copy\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxUq5yHGtp7d",
        "outputId": "0c79c281-7023-48e1-87d9-28c7195ed139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHF4-qE8rKcw"
      },
      "outputs": [],
      "source": [
        "filename = '/final_key_points.csv'\n",
        "\n",
        "TARGET_NAMES_1 = ['Neutral', 'Relaxed', 'Angry & Scared']\n",
        "TARGET_NAMES_2 = ['Alert', 'Neutral_Relaxed', 'Anger_Fear_Anxious']\n",
        "TARGET_NAMES_3 = ['Neutral', 'Relaxed', 'Anger_Fear_Anxious']\n",
        "\n",
        "\n",
        "# read df\n",
        "CSV_OUTPATH = '/content/drive/MyDrive/Coin Project 1/Development_2'\n",
        "df = pd.read_csv(CSV_OUTPATH + filename, dtype=int, index_col=0)\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-1eV-NxX0_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0 = Alert\n",
        "1 = Neutral\n",
        "2 = Relaxed\n",
        "3 = Anger\n",
        "4 = Fear\n",
        "5 = Anxious\n",
        "'''\n",
        "\n",
        "def show_number_of_samples(df):\n",
        "  print('Number of Samples for Class 0: ', len(df[df['emotions'] == 0]))\n",
        "  print('Number of Samples for Class 1: ', len(df[df['emotions'] == 1]))\n",
        "  print('Number of Samples for Class 2: ', len(df[df['emotions'] == 2]))\n",
        "  print('Number of Samples for Class 3: ', len(df[df['emotions'] == 3]))\n",
        "  print('Number of Samples for Class 4: ', len(df[df['emotions'] == 4]))\n",
        "  print('Number of Samples for Class 5: ', len(df[df['emotions'] == 5]))\n",
        "  print('---------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeo6tgVLqyca"
      },
      "outputs": [],
      "source": [
        "# Emotions: Neutral, Relaxed, Anger_Fear\n",
        "df_merged_1 = copy.deepcopy(df)\n",
        "\n",
        "# Merge Anger and Fear to Anger\n",
        "df_merged_1.loc[df['emotions'] == 4, 'emotions'] = 3 # update where emotion=4, set emotion to 3\n",
        "\n",
        "# Delete anxious\n",
        "df_merged_1 = df_merged_1[df_merged_1['emotions'] != 5]\n",
        "\n",
        "# Delete alert\n",
        "df_merged_1 = df_merged_1[df_merged_1['emotions'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpvqlbZJRMYm"
      },
      "outputs": [],
      "source": [
        "# Emotions: Alert, Neutral_Relaxed, Anger_Fear_Anxious\n",
        "df_merged_2 = copy.deepcopy(df)\n",
        "\n",
        "# Merge Anger and Fear to Anger\n",
        "df_merged_2.loc[df['emotions'] == 4, 'emotions'] = 3 # update where emotion=4, set emotion to 3\n",
        "\n",
        "# Merge Anger and Anxious to Anger\n",
        "df_merged_2.loc[df['emotions'] == 5, 'emotions'] = 3 # update where emotion=5, set emotion to 3\n",
        "\n",
        "# Merge Neutral and Relaxed to Neutral\n",
        "df_merged_2.loc[df['emotions'] == 2, 'emotions'] = 1 # update where emotion=5, set emotion to 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srS1ExGURNT2"
      },
      "outputs": [],
      "source": [
        "# Emotions: Neutral, Relaxed, Anger_Fear\n",
        "df_merged_3 = copy.deepcopy(df)\n",
        "\n",
        "# Merge Anger and Fear to Anger\n",
        "df_merged_3.loc[df['emotions'] == 4, 'emotions'] = 3 # update where emotion=4, set emotion to 3\n",
        "\n",
        "# Merge Anger and Anxious to Anger\n",
        "df_merged_3.loc[df['emotions'] == 5, 'emotions'] = 3 # update where emotion=5, set emotion to 3\n",
        "\n",
        "# Delete alert\n",
        "df_merged_3 = df_merged_3[df_merged_3['emotions'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOmtIkOcrgYy"
      },
      "outputs": [],
      "source": [
        "show_number_of_samples(df)\n",
        "show_number_of_samples(df_merged_1)\n",
        "show_number_of_samples(df_merged_2)\n",
        "show_number_of_samples(df_merged_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZVuRHfW8BED"
      },
      "outputs": [],
      "source": [
        "def normalize_df(df):\n",
        "  lengths = []\n",
        "  for i in range(6):\n",
        "    lengths.append(len(df[df['emotions'] == int(i)]))\n",
        "  lengths = [i for i in lengths if i != 0]\n",
        "  smallest_amount = min(lengths)\n",
        "  \n",
        "  # reduce all values to maximum of smallest_amount\n",
        "  df_return = pd.DataFrame({})\n",
        "  for i in range(6):\n",
        "    if len(df[df['emotions'] == int(i)]) != 0:\n",
        "      df_emotion = df[df['emotions'] == int(i)].sample(smallest_amount)\n",
        "      df_return = df_return.append(df_emotion)\n",
        "  return df_return;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMuKurPg8UdF"
      },
      "outputs": [],
      "source": [
        "df_norm_1 = normalize_df(df_merged_1)\n",
        "df_norm_2 = normalize_df(df_merged_2)\n",
        "df_norm_3 = normalize_df(df_merged_3)\n",
        "\n",
        "show_number_of_samples(df_norm_1)\n",
        "show_number_of_samples(df_norm_2)\n",
        "show_number_of_samples(df_norm_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWhyqlTJpzn3"
      },
      "outputs": [],
      "source": [
        "def grid_search_cv(X_train, X_test, y_train, y_test, model, isOVO):\n",
        "  \n",
        "  learning_rate = [0.001, 0.01, 0.10, 0.20, 0.30]\n",
        "  max_depth = [3, 5, 8, 10, 20]\n",
        "  gamma= [0.0, 0.1, 0.2, 1]\n",
        "  n_estimators = [10, 50, 100, 250]\n",
        "  reg_alpha = [0.05, 0.1, 0.5, 1, 5]\n",
        "\n",
        "\n",
        "  hyperparameter_grid = {'learning_rate': learning_rate,\n",
        "                          'max_depth': max_depth,\n",
        "                          'gamma': [0.0, 0.1, 0.2, 0.5, 1],\n",
        "                          'colsample_bytree': [0.3, 0.7, 1.0],\n",
        "                          'reg_alpha': reg_alpha,\n",
        "                          'n_estimators': n_estimators,\n",
        "                          }\n",
        "                          \n",
        "\n",
        "  columns = ['Nose_x','Nose_y','L_Eye_x','L_Eye_y','R_Eye_x','R_Eye_y','L_Ear_x','L_Ear_y','R_Ear_x','R_Ear_y','Throat_x','Throat_y','Withers_x','Withers_y','TailSet_x','TailSet_y','L_F_Paw_x','L_F_Paw_y','R_F_Paw_x','R_F_Paw_y','L_F_Wrist_x','L_F_Wrist_y','R_F_Wrist_x','R_F_Wrist_y','L_F_Elbow_x','L_F_Elbow_y','R_F_Elbow_x','R_F_Elbow_y','L_B_Paw_x','L_B_Paw_y','R_B_Paw_x','R_B_Paw_y','L_B_Hock_x','L_B_Hock_y','R_B_Hock_x','R_B_Hock_y','L_B_Stiffle_x','L_B_Stiffle_y','R_B_Stiffle_x','R_B_Stiffle_y', 'back_middle_x', 'back_middle_y', 'tail_tip_x', 'tail_tip_y', 'lip_upper_x', 'lip_upper_y','lip_lower_x','lip_lower_y', 'ear_tip_left_x', 'ear_tip_left_y', 'ear_tip_right_x', 'ear_tip_right_y']\n",
        "\n",
        "\n",
        "  grid_search_rf = GridSearchCV(estimator = xgb.XGBClassifier(random_state=42), param_grid = hyperparameter_grid, cv = 4, n_jobs = -1, verbose = 1, scoring=\"accuracy\")\n",
        "  # Fit it\n",
        "\n",
        "  if isOVO:\n",
        "    ovo = OneVsOneClassifier(grid_search_rf)\n",
        "    # Fit it\n",
        "    ovo.fit(X_train, y_train)\n",
        "    # Predict the train data\n",
        "    result_train = ovo.predict(X_train)\n",
        "    # Predict the test data\n",
        "    result_test = ovo.predict(X_test)\n",
        "\n",
        "    print(f'Model: {str(model)}; Accuracy for Train Set: {accuracy_score(y_train, result_train)}; Accuracy for Test Set: {accuracy_score(y_test, result_test)}')\n",
        "    print(classification_report(y_test, result_test, target_names=model))\n",
        "    \n",
        "    # Feature Importance\n",
        "    importance_sorted = sorted(zip(grid_search_rf.best_estimator_.feature_importances_, columns), reverse=True)\n",
        "    print()\n",
        "    print(\"Feature Importance: \", importance_sorted)\n",
        "\n",
        "    rf_params = grid_search_rf.best_params_\n",
        "    print()\n",
        "    print(\"Parameter: \", rf_params)\n",
        "\n",
        "    feature_values = [i[0] for i in importance_sorted[0:10]]\n",
        "    feature_names = [i[1] for i in importance_sorted[0:10]]\n",
        "    indices = list(range(0,10))\n",
        "\n",
        "    plt.title('Feature Importances')\n",
        "    plt.barh(range(len(indices)), feature_values, color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "\n",
        "    grid_search_rf.fit(X_train, y_train)\n",
        "    print(\"BEST \", grid_search_rf.best_score_)\n",
        "    # Predict the train data\n",
        "    result_train = grid_search_rf.predict(X_train)\n",
        "    # Predict the test data\n",
        "    result_test = grid_search_rf.predict(X_test)\n",
        "\n",
        "    print(f'Model: {str(model)}; Accuracy for Train Set: {accuracy_score(y_train, result_train)}; Accuracy for Test Set: {accuracy_score(y_test, result_test)}')\n",
        "    print(classification_report(y_test, result_test, target_names=model))\n",
        "    \n",
        "    # Feature Importance\n",
        "    importance_sorted = sorted(zip(grid_search_rf.best_estimator_.feature_importances_, columns), reverse=True)\n",
        "    print()\n",
        "    print(\"Feature Importance: \", importance_sorted)\n",
        "\n",
        "  #   rf_params = grid_search_rf.best_estimator_.getParams(False)\n",
        "    rf_params = grid_search_rf.best_params_\n",
        "    print()\n",
        "    print(\"Parameter: \", rf_params)\n",
        "\n",
        "    feature_values = [i[0] for i in importance_sorted[0:10]]\n",
        "    feature_names = [i[1] for i in importance_sorted[0:10]]\n",
        "    indices = list(range(0,10))\n",
        "\n",
        "    plt.title('Feature Importances')\n",
        "    plt.barh(range(len(indices)), feature_values, color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()\n",
        "\n",
        "    return grid_search_rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0JPyLeNYN96"
      },
      "source": [
        "# XGBoost for Neutral, Relaxed, Anger_Fear (df_norm_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5_ZQ0larzw4"
      },
      "outputs": [],
      "source": [
        "# Train and Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_norm_1, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFZEDg0er1qq"
      },
      "outputs": [],
      "source": [
        "# all rows, but not the first column\n",
        "X_train = train.values[:, 1:]\n",
        "# all rows, but only the first column\n",
        "y_train = train.values[:, :1]\n",
        "\n",
        "X_test = test.values[:, 1:]\n",
        "y_test = test.values[:, :1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tNW9nDfr3Ae"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape((1, len(y_train))).squeeze()\n",
        "y_test = y_test.reshape((1, len(y_test))).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wuTC2Jhs0b7"
      },
      "outputs": [],
      "source": [
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_1, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LFI3rMRDwSfk"
      },
      "outputs": [],
      "source": [
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_1, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coepRSD2cgwO"
      },
      "source": [
        "# XGBoost for Alert, Neutral_Relaxed, Anger_Fear_Anxious (df_norm_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "47N-3nAQcznf"
      },
      "outputs": [],
      "source": [
        "# Train and Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_norm_2, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ERfIK6V1czng"
      },
      "outputs": [],
      "source": [
        "# all rows, but not the first column\n",
        "X_train = train.values[:, 1:]\n",
        "# all rows, but only the first column\n",
        "y_train = train.values[:, :1]\n",
        "\n",
        "X_test = test.values[:, 1:]\n",
        "y_test = test.values[:, :1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NDpKksCbczng"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape((1, len(y_train))).squeeze()\n",
        "y_test = y_test.reshape((1, len(y_test))).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dZoIC3jAzIws"
      },
      "outputs": [],
      "source": [
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_2, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m-g_lumnzJS2"
      },
      "outputs": [],
      "source": [
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_2, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osk45V2MdWVm"
      },
      "source": [
        "# XGBoost for Neutral, Relaxed, Anger_Fear_Anxious (df_norm_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko7LVpGedeI-"
      },
      "outputs": [],
      "source": [
        "# Train and Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_norm_3, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kO2IMZNdeI-"
      },
      "outputs": [],
      "source": [
        "# all rows, but not the first column\n",
        "X_train = train.values[:, 1:]\n",
        "# all rows, but only the first column\n",
        "y_train = train.values[:, :1]\n",
        "\n",
        "X_test = test.values[:, 1:]\n",
        "y_test = test.values[:, :1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhVImCWideI_"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape((1, len(y_train))).squeeze()\n",
        "y_test = y_test.reshape((1, len(y_test))).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3gzQ8vHdeI_"
      },
      "outputs": [],
      "source": [
        "grid_search_rf = grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_3, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ii1Ch4eZzdj5"
      },
      "outputs": [],
      "source": [
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES_3, True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "XGBoost_3_Emotions_All.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}