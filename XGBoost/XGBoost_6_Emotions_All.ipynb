{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGdFhpgkiIBK"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KktEYBWrIMp"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, mean_absolute_percentage_error\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "import copy\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxUq5yHGtp7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHF4-qE8rKcw"
      },
      "outputs": [],
      "source": [
        "filename = '/final_key_points.csv'\n",
        "\n",
        "TARGET_NAMES = ['Alert', 'Neutral', 'Relaxed', 'Anger', 'Fear', 'Anxious']\n",
        "\n",
        "# read df\n",
        "CSV_OUTPATH = '/content/drive/MyDrive/Coin Project 1/Development_2'\n",
        "df = pd.read_csv(CSV_OUTPATH + filename, dtype=int, index_col=0)\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-1eV-NxX0_"
      },
      "outputs": [],
      "source": [
        "def show_number_of_samples(df):\n",
        "  print('Number of Samples for Class Alert: ', len(df[df['emotions'] == 0]))\n",
        "  print('Number of Samples for Class Neutral: ', len(df[df['emotions'] == 1]))\n",
        "  print('Number of Samples for Class Relaxed: ', len(df[df['emotions'] == 2]))\n",
        "  print('Number of Samples for Class Anger: ', len(df[df['emotions'] == 3]))\n",
        "  print('Number of Samples for Class Fear: ', len(df[df['emotions'] == 4]))\n",
        "  print('Number of Samples for Class Anxious: ', len(df[df['emotions'] == 5]))\n",
        "  print('---------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOmtIkOcrgYy"
      },
      "outputs": [],
      "source": [
        "show_number_of_samples(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZVuRHfW8BED"
      },
      "outputs": [],
      "source": [
        "def normalize_df(df):\n",
        "  lengths = []\n",
        "  for i in range(6):\n",
        "    lengths.append(len(df[df['emotions'] == int(i)]))\n",
        "  lengths = [i for i in lengths if i != 0]\n",
        "  smallest_amount = min(lengths)\n",
        "  \n",
        "  # reduce all values to maximum of smallest_amount\n",
        "  df_return = pd.DataFrame({})\n",
        "  for i in range(6):\n",
        "    df_emotion = df[df['emotions'] == int(i)].sample(smallest_amount)\n",
        "    df_return = df_return.append(df_emotion)\n",
        "  return df_return;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMuKurPg8UdF"
      },
      "outputs": [],
      "source": [
        "df_norm = normalize_df(df)\n",
        "show_number_of_samples(df_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5_ZQ0larzw4"
      },
      "outputs": [],
      "source": [
        "# Train and Test split\n",
        "train, test = train_test_split(df_norm, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFZEDg0er1qq"
      },
      "outputs": [],
      "source": [
        "# all rows, but not the first column\n",
        "X_train = train.values[:, 1:]\n",
        "# all rows, but only the first column\n",
        "y_train = train.values[:, :1]\n",
        "\n",
        "X_test = test.values[:, 1:]\n",
        "y_test = test.values[:, :1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tNW9nDfr3Ae"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape((1, len(y_train))).squeeze()\n",
        "y_test = y_test.reshape((1, len(y_test))).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbTFAIbP306P"
      },
      "outputs": [],
      "source": [
        "def grid_search_cv(X_train, X_test, y_train, y_test, model, isOVO):\n",
        "  learning_rate = [0.001, 0.01, 0.10, 0.20, 0.30]\n",
        "  max_depth = [3, 5, 8, 10, 20]\n",
        "  gamma= [0.0, 0.1, 0.2, 1]\n",
        "  n_estimators = [10, 50, 100, 250]\n",
        "  reg_alpha = [0.05, 0.1, 0.5, 1, 5]\n",
        "\n",
        "\n",
        "  hyperparameter_grid = {'learning_rate': learning_rate,\n",
        "                          'max_depth': max_depth,\n",
        "                          'gamma': [0.0, 0.1, 0.2, 0.5, 1],\n",
        "                          'colsample_bytree': [0.3, 0.7, 1.0],\n",
        "                          'reg_alpha': reg_alpha,\n",
        "                          'n_estimators': n_estimators,\n",
        "                          }\n",
        "\n",
        "  columns = ['Nose_x','Nose_y','L_Eye_x','L_Eye_y','R_Eye_x','R_Eye_y','L_Ear_x','L_Ear_y','R_Ear_x','R_Ear_y','Throat_x','Throat_y','Withers_x','Withers_y','TailSet_x','TailSet_y','L_F_Paw_x','L_F_Paw_y','R_F_Paw_x','R_F_Paw_y','L_F_Wrist_x','L_F_Wrist_y','R_F_Wrist_x','R_F_Wrist_y','L_F_Elbow_x','L_F_Elbow_y','R_F_Elbow_x','R_F_Elbow_y','L_B_Paw_x','L_B_Paw_y','R_B_Paw_x','R_B_Paw_y','L_B_Hock_x','L_B_Hock_y','R_B_Hock_x','R_B_Hock_y','L_B_Stiffle_x','L_B_Stiffle_y','R_B_Stiffle_x','R_B_Stiffle_y', 'back_middle_x', 'back_middle_y', 'tail_tip_x', 'tail_tip_y', 'lip_upper_x', 'lip_upper_y','lip_lower_x','lip_lower_y', 'ear_tip_left_x', 'ear_tip_left_y', 'ear_tip_right_x', 'ear_tip_right_y']\n",
        "\n",
        "\n",
        "  grid_search_rf = GridSearchCV(estimator = xgb.XGBClassifier(random_state=42), param_grid = hyperparameter_grid, cv = 4, n_jobs = -1, verbose = 0, scoring=\"accuracy\")\n",
        "  # Fit it\n",
        "  grid_search_rf.fit(X_train, y_train)\n",
        "  print(\"BEST \", grid_search_rf.best_score_)\n",
        "\n",
        "  if isOVO:\n",
        "    ovo = OneVsOneClassifier(grid_search_rf)\n",
        "    # Fit it\n",
        "    ovo.fit(X_train, y_train)\n",
        "    # Predict the train data\n",
        "    result_train = ovo.predict(X_train)\n",
        "    # Predict the test data\n",
        "    result_test = ovo.predict(X_test)\n",
        "\n",
        "    print(f'Model: {str(model)}; Accuracy for Train Set: {accuracy_score(y_train, result_train)}; Accuracy for Test Set: {accuracy_score(y_test, result_test)}')\n",
        "    print(classification_report(y_test, result_test, target_names=model))\n",
        "    \n",
        "    # Feature Importance\n",
        "    importance_sorted = sorted(zip(grid_search_rf.best_estimator_.feature_importances_, columns), reverse=True)\n",
        "    print()\n",
        "    print(\"Feature Importance: \", importance_sorted)\n",
        "\n",
        "    rf_params = grid_search_rf.best_params_\n",
        "    print()\n",
        "    print(\"Parameter: \", rf_params)\n",
        "\n",
        "    feature_values = [i[0] for i in importance_sorted[0:10]]\n",
        "    feature_names = [i[1] for i in importance_sorted[0:10]]\n",
        "    indices = list(range(0,10))\n",
        "\n",
        "    plt.title('Feature Importances')\n",
        "    plt.barh(range(len(indices)), feature_values, color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Predict the train data\n",
        "    result_train = grid_search_rf.predict(X_train)\n",
        "    # Predict the test data\n",
        "    result_test = grid_search_rf.predict(X_test)\n",
        "\n",
        "    print(f'Model: {str(model)}; Accuracy for Train Set: {accuracy_score(y_train, result_train)}; Accuracy for Test Set: {accuracy_score(y_test, result_test)}')\n",
        "    print(classification_report(y_test, result_test, target_names=model))\n",
        "    \n",
        "    # Feature Importance\n",
        "    importance_sorted = sorted(zip(grid_search_rf.best_estimator_.feature_importances_, columns), reverse=True)\n",
        "    print()\n",
        "    print(\"Feature Importance: \", importance_sorted)\n",
        "\n",
        "  #   rf_params = grid_search_rf.best_estimator_.getParams(False)\n",
        "    rf_params = grid_search_rf.best_params_\n",
        "    print()\n",
        "    print(\"Parameter: \", rf_params)\n",
        "\n",
        "    feature_values = [i[0] for i in importance_sorted[0:10]]\n",
        "    feature_names = [i[1] for i in importance_sorted[0:10]]\n",
        "    indices = list(range(0,10))\n",
        "\n",
        "    plt.title('Feature Importances')\n",
        "    plt.barh(range(len(indices)), feature_values, color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ohNZegQz3ogk"
      },
      "outputs": [],
      "source": [
        "# Normal\n",
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dTFN1W5o3oiu"
      },
      "outputs": [],
      "source": [
        "# OVO\n",
        "grid_search_cv(X_train, X_test, y_train, y_test, TARGET_NAMES, True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "XGBoost_6_Emotions_All.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}