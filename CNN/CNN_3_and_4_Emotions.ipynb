{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "CNN_3_and_4_Emotions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision --upgrade"
      ],
      "metadata": {
        "id": "jdOZrgsjId6K"
      },
      "id": "jdOZrgsjId6K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.transforms import GaussianBlur\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "from skimage.transform import rotate\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "FWuVeMI51EjZ"
      },
      "id": "FWuVeMI51EjZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y_wVLQMntVn"
      },
      "source": [
        "# Get device name\n",
        "if torch.cuda.is_available():\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# Assign cuda to device\n",
        "_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "_DEVICE"
      ],
      "id": "6y_wVLQMntVn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MnoVPjXUbkEW"
      },
      "id": "MnoVPjXUbkEW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev2 = '/content/drive/MyDrive/Coin Project 1/Development_2/'\n",
        "pictures_cropped_4_01 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped_4/01'\n",
        "pictures_cropped_4_02 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped_4/02'\n",
        "pictures_cropped_3_01 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped_3/01'\n",
        "pictures_cropped_3_02 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped_3/02'\n",
        "pictures_cropped_3_03 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped_3/03'\n",
        "\n",
        "\n",
        "pictures = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures'\n",
        "pictures_cropped = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped'\n",
        "pictures_test = '/content/drive/MyDrive/Coin Project 1/Development_2/CNN/Test_Data'\n",
        "pictures_train = '/content/drive/MyDrive/Coin Project 1/Development_2/CNN/Train_Data'"
      ],
      "metadata": {
        "id": "aTgzBgM8J2T3"
      },
      "id": "aTgzBgM8J2T3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Delete Train and Test Folder to be able to use them now**"
      ],
      "metadata": {
        "id": "55CZadBR14M-"
      },
      "id": "55CZadBR14M-"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Test Data\n",
        "os.chdir(pictures_test)\n",
        "!ls\n",
        "!rm -rf Alert\n",
        "!rm -rf Anger\n",
        "!rm -rf Anxious\n",
        "!rm -rf Fear\n",
        "!rm -rf Neutral\n",
        "!rm -rf Relaxed\n",
        "!rm -rf Anger_Fear\n",
        "!rm -rf Neutral_Relaxed\n",
        "!rm -rf Anger_Fear_Anxious\n",
        "!ls\n",
        "time.sleep(60) # wait 60 seconds "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY19AdUKddE7",
        "outputId": "a405868d-8712-4d23-9adb-437ad24b9d44"
      },
      "id": "wY19AdUKddE7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anger_Fear  Neutral  Relaxed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Train Data\n",
        "os.chdir(pictures_train)\n",
        "!ls\n",
        "!rm -rf Alert\n",
        "!rm -rf Anger\n",
        "!rm -rf Anxious\n",
        "!rm -rf Neutral_Relaxed\n",
        "!rm -rf Fear\n",
        "!rm -rf Neutral\n",
        "!rm -rf Relaxed\n",
        "!rm -rf Anger_Fear\n",
        "!rm -rf Anger_Fear_Anxious\n",
        "!ls\n",
        "time.sleep(60) # wait 60 seconds "
      ],
      "metadata": {
        "id": "sSKz5wi_c6fw"
      },
      "id": "sSKz5wi_c6fw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Methods to Create new Folders**"
      ],
      "metadata": {
        "id": "slaEGI3h19eR"
      },
      "id": "slaEGI3h19eR"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_6_emotions(where):\n",
        "  os.mkdir(os.path.join(where, 'Alert'))\n",
        "  os.mkdir(os.path.join(where, 'Anger'))\n",
        "  os.mkdir(os.path.join(where, 'Anxious'))\n",
        "  os.mkdir(os.path.join(where, 'Fear'))\n",
        "  os.mkdir(os.path.join(where, 'Neutral'))\n",
        "  os.mkdir(os.path.join(where, 'Relaxed'))"
      ],
      "metadata": {
        "id": "fbEUdHDzb6Ub"
      },
      "id": "fbEUdHDzb6Ub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_4_emotions_01(where):\n",
        "  # Test\n",
        "  os.mkdir(os.path.join(where, 'Alert'))\n",
        "  os.mkdir(os.path.join(where, 'Neutral'))\n",
        "  os.mkdir(os.path.join(where, 'Relaxed'))\n",
        "  os.mkdir(os.path.join(where, 'Anger_Fear'))"
      ],
      "metadata": {
        "id": "3oNGcXwhfWk0"
      },
      "id": "3oNGcXwhfWk0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_4_emotions_02(where):\n",
        "  os.mkdir(os.path.join(where, 'Alert'))\n",
        "  os.mkdir(os.path.join(where, 'Neutral'))\n",
        "  os.mkdir(os.path.join(where, 'Relaxed'))\n",
        "  os.mkdir(os.path.join(where, 'Anger_Fear_Anxious'))"
      ],
      "metadata": {
        "id": "HptNF7Yxf0dU"
      },
      "id": "HptNF7Yxf0dU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_3_emotions_01(where):\n",
        "  os.mkdir(os.path.join(where, 'Neutral'))\n",
        "  os.mkdir(os.path.join(where, 'Relaxed'))\n",
        "  os.mkdir(os.path.join(where, 'Anger_Fear'))"
      ],
      "metadata": {
        "id": "yohVBNW9t9S4"
      },
      "id": "yohVBNW9t9S4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_3_emotions_02(where):\n",
        "  os.mkdir(os.path.join(where, 'Alert'))\n",
        "  os.mkdir(os.path.join(where, 'Neutral_Relaxed'))\n",
        "  os.mkdir(os.path.join(where, 'Anger_Fear_Anxious'))"
      ],
      "metadata": {
        "id": "TuudManquBAl"
      },
      "id": "TuudManquBAl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folders_3_emotions_03(where):\n",
        "  os.mkdir(os.path.join(where, 'Neutral'))\n",
        "  os.mkdir(os.path.join(where, 'Relaxed'))\n",
        "  os.mkdir(os.path.join(where, 'Anger_Fear_Anxious'))"
      ],
      "metadata": {
        "id": "iD1ioFNFvS5Z"
      },
      "id": "iD1ioFNFvS5Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Other Methods**"
      ],
      "metadata": {
        "id": "WL2EiGG_3b7-"
      },
      "id": "WL2EiGG_3b7-"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_length_of_minimum_emotion(path):\n",
        "  sizes = []\n",
        "  for folder in os.listdir(path):\n",
        "    emotion_path = path + '/' + str(folder)\n",
        "    sizes.append(len(os.listdir(emotion_path)))\n",
        "    print('Number of Samples for folder ', folder, ': ', len(os.listdir(emotion_path)))\n",
        "  sizes = [i for i in sizes if i != 0]\n",
        "  print('Sizes: ', sizes)\n",
        "  return min(sizes)"
      ],
      "metadata": {
        "id": "2b8pKDJXS84O"
      },
      "id": "2b8pKDJXS84O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(pictures_cropped_3_01):\n",
        "  print(folder)"
      ],
      "metadata": {
        "id": "-N6kyhTQWqtV"
      },
      "id": "-N6kyhTQWqtV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy Data to Train and Test Folders**"
      ],
      "metadata": {
        "id": "XZDW1O9uglng"
      },
      "id": "XZDW1O9uglng"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Parameters:\n",
        "# emotion_category: '401', '402', '301', '302', '303'\n",
        "# path: path of pictures from where to copy\n",
        "def copy_images_to_train_test_data(emotion_category, path):\n",
        "  if emotion_category is '401':\n",
        "    # create folders\n",
        "    try:\n",
        "      create_folders_4_emotions_01(pictures_train)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    try:\n",
        "      create_folders_4_emotions_01(pictures_test)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  elif emotion_category is '402':\n",
        "    # create folders\n",
        "    try:\n",
        "      create_folders_4_emotions_02(pictures_train)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    try:\n",
        "      create_folders_4_emotions_02(pictures_test)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  elif emotion_category is '301':\n",
        "    # create folders\n",
        "    try:\n",
        "      create_folders_3_emotions_01(pictures_train)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    try:\n",
        "      create_folders_3_emotions_01(pictures_test)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  elif emotion_category is '302':\n",
        "    # create folders\n",
        "    try:\n",
        "      create_folders_3_emotions_02(pictures_train)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    try:\n",
        "      create_folders_3_emotions_02(pictures_test)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  elif emotion_category is '303':\n",
        "    # create folders\n",
        "    try:\n",
        "      create_folders_3_emotions_03(pictures_train)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    try:\n",
        "      create_folders_3_emotions_03(pictures_test)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  else:\n",
        "    print('Emotion Category Unknown!')\n",
        "\n",
        "\n",
        "  # for each emotion folder\n",
        "  for folder in os.listdir(path):\n",
        "\n",
        "    emotion_path = path + '/' + str(folder)\n",
        "    emotion = str(folder)\n",
        "\n",
        "    # get all images inside that emotion folder\n",
        "    all_images = os.listdir(emotion_path)\n",
        "\n",
        "    smallest_amount = get_length_of_minimum_emotion(path)\n",
        "\n",
        "    all_images = all_images[:smallest_amount]\n",
        "    # split into train and test\n",
        "    train_images, test_images = train_test_split(all_images, test_size = 0.2)\n",
        "\n",
        "    print(emotion)\n",
        "    print(len(train_images)), print(len(test_images))\n",
        "    print(\"----------\")\n",
        "\n",
        "    output_folder_test = pictures_test + \"/\" + emotion\n",
        "    output_folder_train = pictures_train + \"/\" + emotion\n",
        "    \n",
        "    for image in train_images:\n",
        "      image_name = os.path.join(emotion_path, image)\n",
        "      shutil.copy(image_name, output_folder_train)\n",
        "\n",
        "    for image in test_images:\n",
        "      image_name = os.path.join(emotion_path, image)\n",
        "      shutil.copy(image_name, output_folder_test)"
      ],
      "metadata": {
        "id": "6t29PUNre8Zc"
      },
      "id": "6t29PUNre8Zc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_images_to_train_test_data('303', pictures_cropped_3_03)"
      ],
      "metadata": {
        "id": "LnmKn6lI3uDi"
      },
      "id": "LnmKn6lI3uDi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**"
      ],
      "metadata": {
        "id": "_Tk79eirgGSh"
      },
      "id": "_Tk79eirgGSh"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    data_CNN = '/content/drive/MyDrive/Coin Project 1/Development_2/CNN'\n",
        "\n",
        "    '''\n",
        "    Image Augmentation:\n",
        "    - Rotate\n",
        "    - Flip (horizontally & vertically)\n",
        "    - Grayscale\n",
        "    - Blur\n",
        "    '''\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "    ])\n",
        "    train_set = datasets.ImageFolder(data_CNN + '/Train_Data', transform = transform)\n",
        "    test_set = datasets.ImageFolder(data_CNN + '/Test_Data', transform = transform)\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "2HhV9YZ8bSd4"
      },
      "id": "2HhV9YZ8bSd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = get_data()\n",
        "image_show_dl = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "6TAoquGGbaV-"
      },
      "id": "6TAoquGGbaV-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_CLASSES = {\n",
        "    0: 'Anger/Fear/Anxious',\n",
        "    1: 'Neutral',\n",
        "    2: 'Relaxed'\n",
        "}"
      ],
      "metadata": {
        "id": "iFM2MJYfGL9p"
      },
      "id": "iFM2MJYfGL9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_imshow():\n",
        "  dataiter = iter(image_show_dl)\n",
        "  images, labels = dataiter.next()\n",
        "  print(labels)\n",
        "  fig, axes = plt.subplots(figsize=(48, 20), ncols=8)\n",
        "  for i in range(8):\n",
        "      ax = axes[i]\n",
        "      ax.imshow(images[i].permute(1, 2, 0)) \n",
        "      ax.title.set_text(' '.join('%5s' % _CLASSES[labels[i].item()]))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8VJnz2RtwuwU"
      },
      "id": "8VJnz2RtwuwU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imshow()"
      ],
      "metadata": {
        "id": "z596WJmdxdW8"
      },
      "id": "z596WJmdxdW8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def accuracy(out, yb):\n",
        "  preds = torch.argmax(out, dim=1)\n",
        "  return (preds == yb).float().mean(), f1_score(yb.cpu(), preds.cpu(), average='weighted')"
      ],
      "metadata": {
        "id": "yFwALF_xKWi2"
      },
      "id": "yFwALF_xKWi2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot\n",
        "import matplotlib.pyplot as plt\n",
        "def plot(loss_train, loss_val, labely, labelx, plotLabel1,plotLabel2):  \n",
        "  # Plot loss\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  ax1.plot(loss_train, color='red', label=plotLabel1)\n",
        "  ax1.plot(loss_val, color='blue', label=plotLabel2)\n",
        "  ax1.set_xlabel(labelx)\n",
        "  ax1.set_ylabel(labely)\n",
        "  ax1.legend()\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "Zj-S7723KdbA"
      },
      "id": "Zj-S7723KdbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "from sklearn.metrics import f1_score\n",
        "import copy\n",
        "\n",
        "def train_model(name, model, train_dl, val_dl , epochs, optimizer, loss_func, batch_size, lr):\n",
        "    print(\"epoch | train loss | train acc | val loss | val acc | test f1 | val f1\")\n",
        "    df = pd.DataFrame({})\n",
        "    loss_train_list = list()\n",
        "    loss_val_list = list()\n",
        "    accuracy_epoch_train = list()\n",
        "    accuracy_epoch_val = list()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      model.train()\n",
        "      total_acc = 0\n",
        "      total_loss = 0\n",
        "      total_f1_score = 0\n",
        "\n",
        "      for xb_train, yb_train in train_dl:\n",
        "        # Move to gpu\n",
        "        xb_train = xb_train.to(_DEVICE)\n",
        "        yb_train = yb_train.to(_DEVICE)\n",
        "        # Clear old gradients from last step\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass \n",
        "        pred = model(xb_train)\n",
        "        # Calculate loss\n",
        "        loss = loss_func(pred, yb_train)\n",
        "        \n",
        "        # Calculate gradients\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        # Add loss and accs\n",
        "        total_loss += loss\n",
        "        accs, score = accuracy(pred, yb_train)\n",
        "        total_acc += accs\n",
        "        total_f1_score += score\n",
        "        \n",
        "      total_loss /= len(train_dl)\n",
        "      total_acc /= len(train_dl)\n",
        "      total_f1_score /= len(train_dl)\n",
        "\n",
        "      total_acc_val = 0\n",
        "      total_loss_val = 0\n",
        "      total_f1_score_val = 0\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for xb_val, yb_val in val_dl:\n",
        "          # Move to gpu\n",
        "          xb_val = xb_val.to(_DEVICE)\n",
        "          yb_val = yb_val.to(_DEVICE)\n",
        "          # Forward pass\n",
        "          pred_val = model(xb_val)\n",
        "          # Calcualte loss\n",
        "          loss_val = loss_func(pred_val, yb_val)\n",
        "\n",
        "          # Add losses and accs\n",
        "          total_loss_val += loss_val\n",
        "          accs_val, score_val = accuracy(pred_val, yb_val)\n",
        "          total_acc_val += accs_val\n",
        "          total_f1_score_val += score_val\n",
        "      \n",
        "      total_acc_val /= len(val_dl)\n",
        "      total_loss_val /= len(val_dl)\n",
        "      total_f1_score_val /= len(val_dl)\n",
        "\n",
        "      #if (epoch+1) % 2 == 0: # save every x iteration\n",
        "      save_model(model.cpu(), name, epoch + 1, batch_size, total_loss.item(), lr)\n",
        "      confusion_matrix_custom(model, val_dl, name, epoch)\n",
        "        #pass\n",
        "\n",
        "      # Debug print\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "      print(f\"  {epoch}   |    {total_loss.item():.4f}  |  {total_acc.item():.4f}   |  {total_loss_val.item():.4f}  |   {total_acc_val.item():.4f} | {total_f1_score:.4f} | {total_f1_score_val:.4f} | \")\n",
        "\n",
        "      # Add losses to list \n",
        "      loss_train_list.append(total_loss.item())\n",
        "      loss_val_list.append(total_loss_val.item())\n",
        "      accuracy_epoch_train.append(total_acc.item())\n",
        "      accuracy_epoch_val.append(total_acc_val.item())\n",
        "\n",
        "      performance = {\n",
        "        'epoch': epoch + 1,\n",
        "        'train_batch_loss': total_loss.item(),\n",
        "        'val_batch_loss': total_loss_val.item(),\n",
        "        'train_acc': total_acc.item(),\n",
        "        'val_acc': total_acc_val.item(),\n",
        "        'train_f1-score': total_f1_score,\n",
        "        'val_f1-score': total_f1_score_val,\n",
        "      }\n",
        "      df = df.append(performance, ignore_index=True)\n",
        "\n",
        "\n",
        "      model = model.to(_DEVICE)\n",
        "\n",
        "    # return loss_train_list, loss_val_list, accuracy_epoch_train, accuracy_epoch_val\n",
        "    save_csv(df, name)\n",
        "    return model"
      ],
      "metadata": {
        "id": "mCo8wbIdKpQo"
      },
      "id": "mCo8wbIdKpQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "def train_all(train_set, val_set, resnet18):\n",
        "  PATH = '/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models'\n",
        "  counter = 0\n",
        "  learning_rates = [0.001, 0.005, 0.01]\n",
        "  batch_sizes = [16, 32]\n",
        "\n",
        "  for batch_size in batch_sizes:   \n",
        "\n",
        "    # dataloader\n",
        "    dataloader_train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "    dataloader_valid = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "    for lr in learning_rates:\n",
        "      if resnet18:\n",
        "        mod = models.resnet18(pretrained=True).to(_DEVICE)\n",
        "      else:\n",
        "        mod = models.resnet152(pretrained=True).to(_DEVICE)\n",
        "\n",
        "      # freeze parameters\n",
        "      for param in mod.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "      # change last output layer\n",
        "      mod.fc.requires_grad = True\n",
        "\n",
        "      if resnet18:\n",
        "        mod.fc = nn.Linear(in_features=512, out_features=4).to(_DEVICE)\n",
        "      else:\n",
        "        mod.fc = nn.Linear(in_features=2048, out_features=4).to(_DEVICE)\n",
        "\n",
        "      # ml configurations\n",
        "      loss_function = nn.CrossEntropyLoss()\n",
        "      epochs = 10\n",
        "      optimizer = torch.optim.Adam(mod.parameters(), lr=lr)\n",
        "\n",
        "      # train model\n",
        "      print('########################################################################################')\n",
        "      print('3.03 ResNet152; Counter ', str(counter), '; Batch-Size: ', str(batch_size), ';LR: ', str(lr))\n",
        "      naming = '3.03 ResNet152; Counter ' + str(counter) + 'Batch-Size: ' + str(batch_size) + 'Learning Rate' + str(lr)\n",
        "      trained_model = train_model(naming, mod, dataloader_train, dataloader_valid, epochs, optimizer, loss_function, batch_size, lr)\n",
        "\n",
        "      # confusion matrix\n",
        "      \n",
        "      trained_model = trained_model.to(device='cpu')\n",
        "      print('########################################################################################')\n",
        "      counter = counter + 1"
      ],
      "metadata": {
        "id": "IeGIm4lJ1jGa"
      },
      "id": "IeGIm4lJ1jGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "def confusion_matrix_custom(model, dataloader_valid, name, epoch):\n",
        "  y_pred = [] \n",
        "  y_true = [] \n",
        "\n",
        "  # iterate over test data\n",
        "  for inputs, labels in dataloader_valid:\n",
        "    labels = labels.to(_DEVICE)\n",
        "    inputs = inputs.to(_DEVICE)\n",
        "    model = model.to(_DEVICE)\n",
        "    output = model(inputs) # Feed Network\n",
        "\n",
        "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy().tolist()\n",
        "    y_pred = y_pred + output # Save Prediction\n",
        "    \n",
        "    labels = labels.data.cpu().numpy().tolist()\n",
        "    y_true = y_true + labels # Save Truth\n",
        "\n",
        "  classes = ('Angry/Scared/Anxious', 'Neutral', 'Relaxed')\n",
        "\n",
        "  # Build confusion matrix\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  df_cm = pd.DataFrame(cf_matrix, index = [i for i in classes], columns = [i for i in classes])\n",
        "  plt.figure(figsize = (12,7))\n",
        "  sn.heatmap(df_cm, annot=True)\n",
        "  plt.savefig('/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models/' + name + '/' + name + '_' + str(epoch) + '_cm.png')\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "WJjhEEzv1lvo"
      },
      "id": "WJjhEEzv1lvo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and Storing ResNet18 Model**"
      ],
      "metadata": {
        "id": "ZiGKylNk8Qyx"
      },
      "id": "ZiGKylNk8Qyx"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_resnet_18(name, path='/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models'):\n",
        "  model = models.resnet18(pretrained=True)\n",
        "  model.fc = nn.Linear(in_features=512, out_features=4)\n",
        "  model.load_state_dict(torch.load(path + '/' + name))\n",
        "  model.eval()"
      ],
      "metadata": {
        "id": "10e_e7BB8Umg"
      },
      "id": "10e_e7BB8Umg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_resnet_152(name, path='/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models'):\n",
        "  model = models.resnet152(pretrained=True)\n",
        "  model.fc = nn.Linear(in_features=2048, out_features=4)\n",
        "  model.load_state_dict(torch.load(path + '/' + name))\n",
        "  model.eval()"
      ],
      "metadata": {
        "id": "PQnyiWRzBP75"
      },
      "id": "PQnyiWRzBP75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "def save_model(model, name, epoch, batch_size, loss, lr, path='/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models'):\n",
        "  output_dir = path + '/' +  name\n",
        "  try:\n",
        "    os.mkdir(output_dir)\n",
        "  except Exception as e:\n",
        "    # already created directory\n",
        "    pass\n",
        "  torch.save(model.state_dict(), output_dir + '/' + name  + '_lr_' + str(lr) + '_epoch_' + str(epoch) + '_loss_' + str(loss))"
      ],
      "metadata": {
        "id": "FZdojc3c7Den"
      },
      "id": "FZdojc3c7Den",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_csv(df, name, path='/content/drive/MyDrive/Coin Project 1/Development_2/Notebooks/Models'):\n",
        "  output_dir = path + '/' +  name\n",
        "  df.to_csv(output_dir +  '/' +  'performance.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "wrORbJue1ddR"
      },
      "id": "wrORbJue1ddR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "O6cPtNAC2V8M"
      },
      "id": "O6cPtNAC2V8M"
    },
    {
      "cell_type": "code",
      "source": [
        "train_all(train_set, val_set, False) # ResNet18 architecture if True"
      ],
      "metadata": {
        "id": "-OThNdB-2X3B"
      },
      "id": "-OThNdB-2X3B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet18**"
      ],
      "metadata": {
        "id": "3jcCOz7MXPnn"
      },
      "id": "3jcCOz7MXPnn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portuguese-cookbook"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "resnet18_pretrained = models.resnet18(pretrained=True).to(_DEVICE)\n",
        "\n",
        "# freeze parameters\n",
        "for param in resnet18_pretrained.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# change last output layer\n",
        "resnet18_pretrained.fc.requires_grad = True\n",
        "resnet18_pretrained.fc = nn.Linear(in_features=512, out_features=4).to(_DEVICE)\n",
        "\n",
        "# Define the number of epochs (the number of training iterations over the entire data set)\n",
        "n_epochs_resnet18_pretrained = 8\n",
        "\n",
        "# Define the learning rate \n",
        "lr_resnet18_pretrained = 0.01\n",
        "\n",
        "# Define the optimizer. Here we will use Stochastic Gradient Descent\n",
        "optimizer_resnet18_pretrained = torch.optim.Adam(resnet18_pretrained.parameters(), lr=lr_resnet18_pretrained)\n",
        "\n",
        "# We will use MSE/NLLLoss as our loss function\n",
        "loss_func_resnet18_pretrained = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Training \n",
        "lossAndAccsList_pretrained = train(resnet18_pretrained, train_dl, val_dl , n_epochs_resnet18_pretrained, optimizer_resnet18_pretrained, loss_func_resnet18_pretrained)\n",
        "plot(lossAndAccsList_pretrained[0], lossAndAccsList_pretrained[1], \"Loss\", \"Epoch\", \"Loss Train\", \"Loss Validation\")\n",
        "plot(lossAndAccsList_pretrained[2], lossAndAccsList_pretrained[3], \"Accuracy\", \"Epoch\", \"Accuracy Train\", \"Accuracy Validation\")"
      ],
      "id": "portuguese-cookbook",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet152**"
      ],
      "metadata": {
        "id": "8Z9weSYRXaeY"
      },
      "id": "8Z9weSYRXaeY"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "resnet152_pretrained = models.resnet152(pretrained=True).to(_DEVICE)\n",
        "\n",
        "# freeze parameters\n",
        "for param in resnet152_pretrained.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# change last output layer\n",
        "resnet152_pretrained.fc.requires_grad = True\n",
        "resnet152_pretrained.fc = nn.Linear(in_features=2048, out_features=4).to(_DEVICE)\n",
        "\n",
        "# check if freezed\n",
        "for param in resnet152_pretrained.parameters():\n",
        "  pass\n",
        "  #print(param.requires_grad)\n",
        "\n",
        "# Define the number of epochs (the number of training iterations over the entire data set)\n",
        "n_epochs_resnet152_pretrained = 8\n",
        "\n",
        "# Define the learning rate \n",
        "lr_resnet152_pretrained = 0.005\n",
        "\n",
        "# Define the optimizer. Here we will use Stochastic Gradient Descent\n",
        "optimizer_resnet152_pretrained = torch.optim.Adam(resnet152_pretrained.parameters(), lr=lr_resnet152_pretrained)\n",
        "\n",
        "# We will use MSE/NLLLoss as our loss function\n",
        "loss_func_resnet152_pretrained = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Training \n",
        "lossAndAccsList_pretrained = train(resnet152_pretrained, train_dl, val_dl , n_epochs_resnet152_pretrained, optimizer_resnet152_pretrained, loss_func_resnet152_pretrained)\n",
        "plot(lossAndAccsList_pretrained[0], lossAndAccsList_pretrained[1], \"Loss\", \"Epoch\", \"Loss Train\", \"Loss Validation\")\n",
        "plot(lossAndAccsList_pretrained[2], lossAndAccsList_pretrained[3], \"Accuracy\", \"Epoch\", \"Accuracy Train\", \"Accuracy Validation\")"
      ],
      "metadata": {
        "id": "3K1UPr_XXfdp"
      },
      "id": "3K1UPr_XXfdp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Individual Predictions**"
      ],
      "metadata": {
        "id": "SK9bSIjISOuT"
      },
      "id": "SK9bSIjISOuT"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessImageFromPath(imagePath):\n",
        "  img = Image.open(imagePath)\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "    ])\n",
        "  \n",
        "  img_tensor = transform(img).float()\n",
        "  return img_tensor"
      ],
      "metadata": {
        "id": "GglRkuySA-pN"
      },
      "id": "GglRkuySA-pN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_result(y_hat):\n",
        "  tmp = y_hat.squeeze().tolist()\n",
        "  max_val = max(tmp)\n",
        "  predicted_class = tmp.index(max_val)\n",
        "  print('Predicted Class: ', predicted_class)"
      ],
      "metadata": {
        "id": "ONIg2zpLSw-t"
      },
      "id": "ONIg2zpLSw-t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image(model, picture_path):\n",
        "  image = preprocessImageFromPath(picture_path)\n",
        "  image = image.unsqueeze(0)\n",
        "  # Predict image\n",
        "  image = image.to(device=_DEVICE)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    prediction = model(image)\n",
        "    prediction_class = _CLASSES[np.argmax(prediction.to(device='cpu')).item()]\n",
        "    print('Cat Emotion Prediction: ', prediction_class)"
      ],
      "metadata": {
        "id": "RMCKZPdNDWqF"
      },
      "id": "RMCKZPdNDWqF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fear_picture = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_to_predict/alert_100.jpg'\n",
        "classify_image(resnet18_pretrained, fear_picture)"
      ],
      "metadata": {
        "id": "3R6qi9T6G7AW"
      },
      "id": "3R6qi9T6G7AW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_picture(pic):\n",
        "  pic = pic.to(device=device)\n",
        "  with torch.no_grad():\n",
        "    #pred_1 = resnet18_pretrained(tensor_angry)\n",
        "    pred_2 = resnet18_pretrained(pic)\n",
        "    print(np.argmax(pred_2.to(device='cpu')).item())"
      ],
      "metadata": {
        "id": "SUOjGWQkKG6J"
      },
      "id": "SUOjGWQkKG6J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_picture(fear_picture)"
      ],
      "metadata": {
        "id": "hSDGByVlTerQ"
      },
      "id": "hSDGByVlTerQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "save_path = \"/content/drive/MyDrive/Coin Project 1/Development_2/resnet_model_coin\"\n",
        "torch.save(resnet18_pretrained.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "iw8ZIfAAI4VY"
      },
      "id": "iw8ZIfAAI4VY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "resnet18_pretrained_loaded = models.resnet18(pretrained=True)\n",
        "resnet18_pretrained_loaded.fc = nn.Linear(in_features=512, out_features=6).to(device)\n",
        "\n",
        "resnet18_pretrained_loaded.load_state_dict(torch.load(save_path))\n",
        "resnet18_pretrained_loaded.eval()"
      ],
      "metadata": {
        "id": "OkbupkMgMEuP"
      },
      "id": "OkbupkMgMEuP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_name)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((128, 128)),\n",
        "    ])\n",
        "\n",
        "    image = transform(image).float()\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)  # this is for VGG, may not be needed for ResNet\n",
        "    return image.cuda()  # assumes that you're using GPU\n",
        "\n",
        "image = image_loader(\"/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_to_predict/angry.png\")\n",
        "\n",
        "resnet18_pretrained(image)"
      ],
      "metadata": {
        "id": "-YQBIJaMTBIk"
      },
      "id": "-YQBIJaMTBIk",
      "execution_count": null,
      "outputs": []
    }
  ]
}