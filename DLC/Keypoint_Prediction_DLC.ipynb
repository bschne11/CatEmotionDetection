{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keypoint_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install imageai\n",
        "!pip install deeplabcut\n",
        "!pip install tensorflow-object-detection-\n",
        "!pip install imagehash\n",
        "!pip install pillow\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "id": "eV2LqEyVLeOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S_IvEK1y7xXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set path to our training data pictures with different emotions as subfolders\n",
        "# data_pictures_origin = '/content/drive/MyDrive/Coin Project 1/Pictures'\n",
        "data_pictures = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Without_Duplicates'\n",
        "data_pictures_cropped = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Cropped'\n",
        "data_pictures_labeled = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Labeled'\n",
        "data_pictures_labeled2 = '/content/drive/MyDrive/Coin Project 1/Development_2/Pictures_Labeled2'"
      ],
      "metadata": {
        "id": "OPQy6tdQYNTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the Images\n",
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# set model path to private google drive\n",
        "model_path = '/content/drive/MyDrive/Coin Project 1/Develpment/DLC/resnet50_coco_best_v2.1.0.h5'\n",
        "\n",
        "object_detector = ObjectDetection() \n",
        "object_detector.setModelTypeAsRetinaNet()\n",
        "object_detector.setModelPath(model_path)\n",
        "object_detector.loadModel()\n",
        "custom_cat = object_detector.CustomObjects(cat=True)"
      ],
      "metadata": {
        "id": "K6743KDt7BEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padding = 0.1\n",
        "# change directory to pictures\n",
        "os.chdir(data_pictures)\n",
        "\n",
        "# for each emotion folder\n",
        "for folder in os.listdir(data_pictures):\n",
        "\n",
        "  print(\"Begin cropping images from folder \", folder)\n",
        "  picture_counter = 0 # counter for number of pictures per emotion\n",
        "  emotion_path = data_pictures + '/' + str(folder)\n",
        "  # for each file inside the emotion folder\n",
        "  for file_name in os.listdir(emotion_path):\n",
        "    input_image_path = emotion_path + '/' + file_name\n",
        "    output_image_path = data_pictures_cropped + '/' + str(folder) + '/' + str(folder) + '_' + str(picture_counter) + '.jpg'\n",
        "    \n",
        "    # detect our cat in picture\n",
        "    detections = object_detector.detectObjectsFromImage(\n",
        "        input_image=input_image_path,\n",
        "        output_image_path=output_image_path,\n",
        "        minimum_percentage_probability=10,\n",
        "        custom_objects=custom_cat)\n",
        "    \n",
        "    if detections: # if cat got detected with enough probability\n",
        "      image = cv2.imread(input_image_path)\n",
        "      height, width, channels = image.shape\n",
        "\n",
        "      cat = (sorted(detections, key=lambda cat: cat['percentage_probability'], reverse=True))[0]\n",
        "\n",
        "      # Retrieve edge coordinates for the detected cat, padding for certainty\n",
        "      x1 = max(0, int(cat['box_points'][0] * (1 - padding)))\n",
        "      y1 = max(0, int(cat['box_points'][1] * (1 - padding)))\n",
        "      x2 = min(width, int(cat['box_points'][2] * (1 + padding)))\n",
        "      y2 = min(width, int(cat['box_points'][3] * (1 + padding)))\n",
        "\n",
        "      image = image[y1:y2, x1:x2]\n",
        "      if image.size:\n",
        "        cv2.imwrite(output_image_path, image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "        picture_counter += 1\n",
        "      else: print('Empty Image')\n",
        "    else: print('No cat detected: ' + input_image_path)"
      ],
      "metadata": {
        "id": "z_q-hp4mhji1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze_time_lapse_frames \n",
        "import deeplabcut\n",
        "from deeplabcut.pose_estimation_tensorflow.config import load_config\n",
        "from deeplabcut.pose_estimation_tensorflow.core import predict\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "#project_config = '/content/drive/MyDrive/Coin Project 1/Develpment/DLC/COINs-Cat-Emotions-Team-01-2022-04-21-20220421T063744Z-001.zip (Unzipped Files)/COINs-Cat-Emotions-Team-01-2022-04-21/config.yaml'\n",
        "path_train_config_full_cat = '/content/drive/MyDrive/Coin Project 1/Develpment/DLC/COINs-Cat-Emotions-Team-01-2022-04-21-20220421T063744Z-001.zip (Unzipped Files)/COINs-Cat-Emotions-Team-01-2022-04-21/dlc-models/iteration-0/COINs-Cat-EmotionsApr21-trainset95shuffle1/train/pose_cfg.yaml'\n",
        "#Todo\n",
        "path_train_config_own_labels = '/content/drive/MyDrive/Coin Project 1/Development_2/DLC_New_Keypoints/Emotion_Recognition_in_Cats-Sofie.zip (Unzipped Files)/Emotion_Recognition_in_Cats-Sofie/dlc-models/iteration-0/Emotion_Recognition_in_CatsMay31-trainset80shuffle1/train/pose_cfg.yaml'\n",
        "\n",
        "dlc_cfg_full_cat = load_config(str(path_train_config_full_cat))\n",
        "dlc_cfg_own_labels = load_config(str(path_train_config_own_labels))\n",
        "print(dlc_cfg_full_cat)\n",
        "print()\n",
        "print(dlc_cfg_own_labels)\n",
        "print()\n",
        "\n",
        "sess_full_cat, inputs_full_cat, outputs_full_cat = predict.setup_pose_prediction(dlc_cfg_full_cat)      # sess, inputs, outputs\n",
        "sess_own_labels, inputs_own_labels, outputs_own_labels = predict.setup_pose_prediction(dlc_cfg_own_labels)      # sess, inputs, outputs"
      ],
      "metadata": {
        "id": "OfbV5W_wcFaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getEmotionFromPath(imagePath):\n",
        "  if \"Alert\" in imagePath: return 0\n",
        "  elif \"Neutral\" in imagePath: return 1\n",
        "  elif \"Relaxed\" in imagePath: return 2\n",
        "  elif \"Anger\" in imagePath: return 3\n",
        "  elif \"Fear\" in imagePath: return 4\n",
        "  elif \"Anxious\" in imagePath: return 5\n",
        "  else: return -1\n",
        "\n",
        "def getEmotionFromPathMerged(imagePath):\n",
        "  if \"Alert\" in imagePath: return 0\n",
        "  elif \"Neutral\" in imagePath: return 1\n",
        "  elif \"Relaxed\" in imagePath: return 2\n",
        "  elif \"Anger_Fear\" in imagePath: return 3\n",
        "  else: return -1"
      ],
      "metadata": {
        "id": "Pwkyw6eZ4mnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper methods\n",
        "\n",
        "# check if keypoint was found\n",
        "def keypoint_found(point):\n",
        "    if point == [-1,-1]: return False # no keypoint found \n",
        "    return True\n",
        "\n",
        "\n",
        "# method to check a list of x and y coordinates\n",
        "# the first one that has a x and y coordinate will be returned\n",
        "def get_first_keypoint(pointList):\n",
        "    for point in pointList:\n",
        "        if keypoint_found(point): return point\n",
        "    return None\n",
        "\n",
        "# mirroring the image horizontally along the vertical axis\n",
        "def mirror_image(point):\n",
        "    if keypoint_found(point): return [resizeWidth - point[0], point[1]]\n",
        "    else: return point"
      ],
      "metadata": {
        "id": "oALTB1sA9q3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Cat's body parts: Numbering, Body Part, (Column for X Coordinate, Column for Y Coordinate)\n",
        "- 0 - Nose (1,2)\n",
        "- 1 - L_Eye (3,4)\n",
        "- 2 - R_Eye (5,6)\n",
        "- 3 - L_Ear (7,8)\n",
        "- 4 - R_Ear (9,10)\n",
        "- 5 - Throat (11,12)\n",
        "- 6 - Withers (13,14)\n",
        "- 7 - TailSet (15,16)\n",
        "- 8 - L_F_Paw (17,18)\n",
        "- 9 - R_F_Paw (19,20)\n",
        "- 10 - L_F_Wrist (21,22)\n",
        "- 11 - R_F_Wrist (23,24)\n",
        "- 12 - L_F_Elbow (25,26)\n",
        "- 13 - R_F_Elbow (27,28)\n",
        "- 14 - L_B_Paw (29,30)\n",
        "- 15 - R_B_Paw (31,32)\n",
        "- 16 - L_B_Hock (33,34)\n",
        "- 17 - R_B_Hock (35,36)\n",
        "- 18 - L_B_Stiffle (37,38)\n",
        "- 19 - R_B_Stiffle (39,40)\n",
        "'''\n",
        "\n",
        "\n",
        "def check_cat_direction_and_rename_columns(data, isFullCat):\n",
        "  # create df from data\n",
        "  df = pd.DataFrame(data)\n",
        "  data_out = []\n",
        "\n",
        "  if isFullCat:\n",
        "    # define keypoints\n",
        "    for index, row in df.iterrows():\n",
        "      emotion = row[0]\n",
        "\n",
        "      Nose = [row[1], row[2]]\n",
        "      L_Eye = [row[3], row[4]]\n",
        "      R_Eye = [row[5], row[6]]\n",
        "      L_Ear = [row[7], row[8]]\n",
        "      R_Ear = [row[9], row[10]]\n",
        "      Throat = [row[11], row[12]]\n",
        "      Withers = [row[13], row[14]]\n",
        "      TailSet = [row[15], row[16]]\n",
        "      L_F_Paw = [row[17], row[18]]\n",
        "      R_F_Paw = [row[19], row[20]]\n",
        "      L_F_Wrist = [row[21], row[22]]\n",
        "      R_F_Wrist = [row[23], row[24]]\n",
        "      L_F_Elbow  = [row[25], row[26]]\n",
        "      R_F_Elbow  = [row[27], row[28]]\n",
        "      L_B_Paw  = [row[29], row[30]]\n",
        "      R_B_Paw  = [row[31], row[32]]\n",
        "      L_B_Hock  = [row[33], row[34]]\n",
        "      R_B_Hock  = [row[35], row[36]]\n",
        "      L_B_Stiffle  = [row[37], row[38]]\n",
        "      R_B_Stiffle  = [row[39], row[40]]\n",
        "\n",
        "      # get first keypoint that is available in list\n",
        "      back = get_first_keypoint([TailSet, L_B_Paw, R_B_Paw])\n",
        "      front = get_first_keypoint([Nose, L_Eye, R_Eye, Throat])\n",
        "\n",
        "      # if cat is looking into right direction, mirror image on vertical axis. Then cat is looking left\n",
        "      if back is not None and front is not None:\n",
        "        if front[0] > back[0]:\n",
        "          Nose = mirror_image(Nose)\n",
        "          L_Eye = mirror_image(L_Eye)\n",
        "          R_Eye = mirror_image(R_Eye)\n",
        "          L_Ear = mirror_image(L_Ear)\n",
        "          R_Ear = mirror_image(R_Ear)\n",
        "          Throat = mirror_image(Throat)\n",
        "          Withers = mirror_image(Withers)\n",
        "          TailSet = mirror_image(TailSet)\n",
        "          L_F_Paw = mirror_image(L_F_Paw)\n",
        "          R_F_Paw = mirror_image(R_F_Paw)\n",
        "          L_F_Wrist = mirror_image(L_F_Wrist)\n",
        "          R_F_Wrist = mirror_image(R_F_Wrist)\n",
        "          L_F_Elbow  = mirror_image(L_F_Elbow)\n",
        "          R_F_Elbow  = mirror_image(R_F_Elbow)\n",
        "          L_B_Paw  = mirror_image(L_B_Paw)\n",
        "          R_B_Paw  = mirror_image(R_B_Paw)\n",
        "          L_B_Hock  = mirror_image(L_B_Hock)\n",
        "          R_B_Hock  = mirror_image(R_B_Hock)\n",
        "          L_B_Stiffle  = mirror_image(L_B_Stiffle)\n",
        "          R_B_Stiffle  = mirror_image(R_B_Stiffle)\n",
        "\n",
        "      data_out.append([emotion, Nose[0], Nose[1], L_Eye[0], L_Eye[1], R_Eye[0], R_Eye[1], L_Ear[0], L_Ear[1], R_Ear[0], R_Ear[1], Throat[0], Throat[1], Withers[0], Withers[1], TailSet[0], TailSet[1], L_F_Paw[0], L_F_Paw[1], R_F_Paw[0], R_F_Paw[1], L_F_Wrist[0], L_F_Wrist[1],\n",
        "                      R_F_Wrist[0],R_F_Wrist[1], L_F_Elbow[0], L_F_Elbow[1], R_F_Elbow[0], R_F_Elbow[1], L_B_Paw[0], L_B_Paw[1], R_B_Paw[0], R_B_Paw[1], L_B_Hock[0], L_B_Hock[1], R_B_Hock[0], R_B_Hock[1], L_B_Stiffle[0], L_B_Stiffle[1], R_B_Stiffle[0], R_B_Stiffle[1]])\n",
        "\n",
        "    return pd.DataFrame(data = data_out, columns = ['emotions', 'Nose_x','Nose_y','L_Eye_x','L_Eye_y','R_Eye_x','R_Eye_y','L_Ear_x','L_Ear_y','R_Ear_x','R_Ear_y','Throat_x','Throat_y','Withers_x','Withers_y','TailSet_x','TailSet_y','L_F_Paw_x','L_F_Paw_y','R_F_Paw_x','R_F_Paw_y','L_F_Wrist_x','L_F_Wrist_y','R_F_Wrist_x','R_F_Wrist_y','L_F_Elbow_x','L_F_Elbow_y','R_F_Elbow_x','R_F_Elbow_y','L_B_Paw_x','L_B_Paw_y','R_B_Paw_x','R_B_Paw_y','L_B_Hock_x','L_B_Hock_y','R_B_Hock_x','R_B_Hock_y','L_B_Stiffle_x','L_B_Stiffle_y','R_B_Stiffle_x','R_B_Stiffle_y'])\n",
        "\n",
        "  else:\n",
        "    for index, row in df.iterrows():\n",
        "      emotion = row[0]\n",
        "\n",
        "      back_middle = [row[1], row[2]]\n",
        "      tail_tip = [row[3], row[4]]\n",
        "      lip_upper = [row[5], row[6]]\n",
        "      lip_lower = [row[7], row[8]]\n",
        "      ear_tip_left = [row[9], row[10]]\n",
        "      ear_base_left = [row[11], row[12]]\n",
        "      ear_tip_right = [row[13], row[14]]\n",
        "      ear_base_right = [row[15], row[16]]\n",
        "\n",
        "      # get first keypoint that is available in list\n",
        "      back = get_first_keypoint([tail_tip, back_middle])\n",
        "      front = get_first_keypoint([lip_lower, lip_lower, ear_tip_left, ear_tip_right])\n",
        "\n",
        "      # if cat is looking into right direction, mirror image on vertical axis. Then cat is looking left\n",
        "      if back is not None and front is not None:\n",
        "        if front[0] > back[0]:\n",
        "          back_middle = mirror_image(back_middle)\n",
        "          tail_tip = mirror_image(tail_tip)\n",
        "          lip_upper = mirror_image(lip_upper)\n",
        "          lip_lower = mirror_image(lip_lower)\n",
        "          ear_tip_left = mirror_image(ear_tip_left)\n",
        "          ear_base_left = mirror_image(ear_base_left)\n",
        "          ear_tip_right = mirror_image(ear_tip_right)\n",
        "          ear_base_right = mirror_image(ear_base_right)\n",
        "\n",
        "      data_out.append([emotion, back_middle[0], back_middle[1], tail_tip[0], tail_tip[1], lip_upper[0], lip_upper[1], lip_lower[0], lip_lower[1], \n",
        "                       ear_tip_left[0], ear_tip_left[1], ear_base_left[0], ear_base_left[1], ear_tip_right[0], ear_tip_right[1], ear_base_right[0], ear_base_right[1]])\n",
        "\n",
        "      '''\n",
        "      - back_middle\n",
        "      - tail_tip\n",
        "      - lip_upper\n",
        "      - lip_lower\n",
        "      - ear_tip_left\n",
        "      - ear_base_left\n",
        "      - ear_tip_right\n",
        "      - ear_base_right\n",
        "      '''\n",
        "    print(data_out)\n",
        "    return pd.DataFrame(data = data_out, columns = ['emotion', 'back_middle_x', 'back_middle_y', 'tail_tip_x', 'tail_tip_y', 'lip_upper_x', 'lip_upper_y','lip_lower_x','lip_lower_y', 'ear_tip_left_x', 'ear_tip_left_y', 'ear_base_left_x', 'ear_base_left_y', 'ear_tip_right_x', 'ear_tip_right_y', 'ear_base_right_x', 'ear_base_right_y'])"
      ],
      "metadata": {
        "id": "Lel6Je3y_f_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resizing images before using deeplabcut\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.util import img_as_ubyte\n",
        "import cv2\n",
        "\n",
        "resizeWidth = 300\n",
        "data = []\n",
        "\n",
        "os.chdir(data_pictures_cropped)\n",
        "for folder in sorted(os.listdir(data_pictures_cropped)):\n",
        "  print(f'Starting with folder {folder}')\n",
        "  for filename in sorted(os.listdir(folder)):\n",
        "\n",
        "    if filename != '.DS_Store':\n",
        "      pathImage = data_pictures_cropped + '/' + folder + '/' + filename\n",
        "      image = imread(pathImage)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      # print(f'Before Width: {width}; Before Height: {height}')\n",
        "\n",
        "      resizeHeight = int(round(height * resizeWidth / width))\n",
        "      image = resize(image, (resizeHeight, resizeWidth), anti_aliasing=False)\n",
        "      # print(f'After Width: {image.shape[0]}; After Height: {image.shape[1]}')\n",
        "      frame = img_as_ubyte(image)\n",
        "\n",
        "      # Todo: SET THE RIGHT MODEL HERE: EITHER own_labels or full_cat\n",
        "      pose = predict.getpose(frame, dlc_cfg_own_labels, sess_own_labels, inputs_own_labels, outputs_own_labels)\n",
        "\n",
        "      scaleFactor = width / resizeWidth\n",
        "\n",
        "      image = cv2.imread(pathImage)\n",
        "      coordinates = []\n",
        "      counterPoint = 0\n",
        "\n",
        "      # add emotion\n",
        "      coordinates.append(getEmotionFromPath(pathImage))\n",
        "\n",
        "      for keypoint in pose:\n",
        "        if (keypoint[2] > 0.1):\n",
        "          x = int(round(keypoint[0]*1))\n",
        "          y = int(round(keypoint[1]*1))\n",
        "\n",
        "\n",
        "          \n",
        "          '''#Remember, try this!\n",
        "          x = int(round(keypoint[0]*scaleFactor))\n",
        "          y = int(round(keypoint[1]*scaleFactor))'''\n",
        "          \n",
        "\n",
        "\n",
        "          # Only if you want to label the pictures\n",
        "          cv2.putText(image, str(counterPoint), (int(round(x*scaleFactor)),int(round(y*scaleFactor))), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "          coordinates.append(x)\n",
        "          coordinates.append(y)\n",
        "        else:\n",
        "          coordinates.append(-1)\n",
        "          coordinates.append(-1)\n",
        "        counterPoint += 1\n",
        "      \n",
        "      # Only if you want to store the labeled pictures\n",
        "      out_path_final = data_pictures_labeled2 + '/' + folder + '/' + filename\n",
        "      cv2.imwrite(out_path_final, image) # write to labeled\n",
        "      data.append(coordinates)"
      ],
      "metadata": {
        "id": "Vaj4VsndXoew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "# check if we need to flip the picture because the cat is not looking to the left\n",
        "# True = Full Cat, False = Own Key Points\n",
        "df = check_cat_direction_and_rename_columns(data, False)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "I0AhUCR6MIvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_OUTPATH = '/content/drive/MyDrive/Coin Project 1/Development_2'\n",
        "df.info()\n",
        "\n",
        "filename = '/data_6_emotions_full_cat.csv'\n",
        "filename_2 = '/new_key_points.csv'\n",
        "filename_final = '/final_key_points.csv'\n",
        "\n",
        "df.to_csv(CSV_OUTPATH + filename_2)"
      ],
      "metadata": {
        "id": "5VDGS2SVhUrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_cat_points = pd.read_csv(CSV_OUTPATH + filename).reset_index()\n",
        "new_points = pd.read_csv(CSV_OUTPATH + filename_2).reset_index()\n",
        "# Check if the emotions of the full_cat and the ones of the new_points are equal for all rows\n",
        "is_equal = full_cat_points[\"emotions\"].equals(new_points['emotion'])\n",
        "print(is_equal)"
      ],
      "metadata": {
        "id": "wiC0UoiVYliT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_equal:\n",
        "  all_points = pd.concat([full_cat_points, new_points], axis=1)"
      ],
      "metadata": {
        "id": "ulgw0yPkdC1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_points.info()"
      ],
      "metadata": {
        "id": "8_OBIDROeTbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_2.to_csv(CSV_OUTPATH + filename_final)"
      ],
      "metadata": {
        "id": "W0cuBXjbb2Aj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}